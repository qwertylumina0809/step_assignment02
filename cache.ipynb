{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorry I still haven't finished all the questions.\n",
    "# I created the data structure of Doubly Linked List but it takes O(n) to search. \n",
    "# I know that if I can sucessfully use dict(hash table) then it only takes O(1) to serach. \n",
    "# But I don't know how, could you please give me some hints? Thank you =)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, key=None, value=None, prev=None, next=None):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "        \n",
    "class DoublyLinkList:\n",
    "    \n",
    "    def __init__(self,capacity):\n",
    "        self.capacity = capacity\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        self.size = 0\n",
    "        \n",
    "    def add_head(self,node):\n",
    "        if not self.head:\n",
    "            self.head = node\n",
    "            self.tail = node\n",
    "            self.head.prev = None\n",
    "            self.head.next = None\n",
    "        else:\n",
    "            node.next = self.head\n",
    "            self.head.prev = node\n",
    "            self.head = node\n",
    "            self.head.prev = None\n",
    "            self.size += 1\n",
    "            return node\n",
    "    \n",
    "    def delete_tail(self):\n",
    "        if not self.tail:\n",
    "            return\n",
    "        node = self.tail\n",
    "        if node.prev:\n",
    "            self.tail = node.prev\n",
    "            self.tail.next = None\n",
    "        else:\n",
    "            self.head = self.tail = None\n",
    "        self.size -= 1\n",
    "        return node\n",
    "    \n",
    "    def delete_head(self):\n",
    "        if not self.head:\n",
    "            return\n",
    "        node = self.head\n",
    "        if node.next:\n",
    "            self.head = node.next\n",
    "            self.head.prev = None\n",
    "        else:\n",
    "            self.tail = self.head = None\n",
    "        self.size -= 1\n",
    "        return node\n",
    "    \n",
    "    def remove(self,node):\n",
    "        if not node:\n",
    "            node = self.tail\n",
    "        if node == self.tail:\n",
    "            self.delete_tail()\n",
    "        elif node == self.head:\n",
    "            self.delete_head\n",
    "        else:\n",
    "            node.prev.net = node.next\n",
    "            node.next.prev = node.prev\n",
    "            self.size -= 1\n",
    "        return node\n",
    "    \n",
    "    def search(self,url):\n",
    "        current = self.head\n",
    "        while current is not None:\n",
    "            if current.key == url:\n",
    "                self.remove(current)\n",
    "                return node\n",
    "            else:\n",
    "                current = current.next\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Cache is a data structure that stores the most recently accessed N pages.\n",
    "# See the below test cases to see how it should work.\n",
    "#\n",
    "# Note: Please do not use a library (e.g., collections.OrderedDict).\n",
    "#       Implement the data structure yourself.\n",
    "class Cache:\n",
    "  # Initializes the cache.\n",
    "  # |n|: The size of the cache.\n",
    "  def __init__(self, n):\n",
    "    self.size = n\n",
    "    self.stored = DoublyLinkList(n)\n",
    "    \n",
    "  # Access a page and update the cache so that it stores the most\n",
    "  # recently accessed N pages. This needs to be done with mostly O(1).\n",
    "  # |url|: The accessed URL\n",
    "  # |contents|: The contents of the URL\n",
    "  def access_page(self, url, contents):\n",
    "    if self.stored.search(url):\n",
    "        node = Node(url,contents)\n",
    "    \n",
    "    if self.stored.size < 5:\n",
    "        node = Node(url,contents)\n",
    "        self.stored.add_head(node)\n",
    "    else:\n",
    "        l.delete_tail()\n",
    "        node = Node(url,contents)\n",
    "        self.stored.add_head(node)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "  # Return the URLs stored in the cache. The URLs are ordered\n",
    "  # in the order in which the URLs are mostly recently accessed.\n",
    "  def get_pages(self):\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.access_page('AAA.com','aaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.access_page('BBB.com','bbb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.access_page('C.com','ccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.access_page('AAA.com','aaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does your code pass all test cases? :)\n",
    "def cache_test():\n",
    "  # Set the size of the cache to 4.\n",
    "  cache = Cache(4)\n",
    "  # Initially, no page is cached.\n",
    "  equal(cache.get_pages(), [])\n",
    "  # Access \"a.com\".\n",
    "  cache.access_page(\"a.com\", \"AAA\")\n",
    "  # \"a.com\" is cached.\n",
    "  equal(cache.get_pages(), [\"a.com\"])\n",
    "  # Access \"b.com\".\n",
    "  cache.access_page(\"b.com\", \"BBB\")\n",
    "  # The cache is updated to:\n",
    "  #   (most recently accessed)<-- \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "  equal(cache.get_pages(), [\"b.com\", \"a.com\"])\n",
    "  # Access \"c.com\".\n",
    "  cache.access_page(\"c.com\", \"CCC\")\n",
    "  # The cache is updated to:\n",
    "  #   (most recently accessed)<-- \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "  equal(cache.get_pages(), [\"c.com\", \"b.com\", \"a.com\"])\n",
    "  # Access \"d.com\".\n",
    "  cache.access_page(\"d.com\", \"DDD\")\n",
    "  # The cache is updated to:\n",
    "  #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "  equal(cache.get_pages(), [\"d.com\", \"c.com\", \"b.com\", \"a.com\"])\n",
    "  # Access \"d.com\" again.\n",
    "  cache.access_page(\"d.com\", \"DDD\")\n",
    "  # The cache is updated to:\n",
    "  #   (most recently accessed)<-- \"d.com\", \"c.com\", \"b.com\", \"a.com\" -->(least recently accessed)\n",
    "  equal(cache.get_pages(), [\"d.com\", \"c.com\", \"b.com\", \"a.com\"])\n",
    "  # Access \"a.com\" again.\n",
    "  cache.access_page(\"a.com\", \"AAA\")\n",
    "  # The cache is updated to:\n",
    "  #   (most recently accessed)<-- \"a.com\", \"d.com\", \"c.com\", \"b.com\" -->(least recently accessed)\n",
    "  equal(cache.get_pages(), [\"a.com\", \"d.com\", \"c.com\", \"b.com\"])\n",
    "  cache.access_page(\"c.com\", \"CCC\")\n",
    "  equal(cache.get_pages(), [\"c.com\", \"a.com\", \"d.com\", \"b.com\"])\n",
    "  cache.access_page(\"a.com\", \"AAA\")\n",
    "  equal(cache.get_pages(), [\"a.com\", \"c.com\", \"d.com\", \"b.com\"])\n",
    "  cache.access_page(\"a.com\", \"AAA\")\n",
    "  equal(cache.get_pages(), [\"a.com\", \"c.com\", \"d.com\", \"b.com\"])\n",
    "  # Access \"e.com\".\n",
    "  cache.access_page(\"e.com\", \"EEE\")\n",
    "  # The cache is full, so we need to remove the least recently accessed page \"b.com\".\n",
    "  # The cache is updated to:\n",
    "  #   (most recently accessed)<-- \"e.com\", \"a.com\", \"c.com\", \"d.com\" -->(least recently accessed)\n",
    "  equal(cache.get_pages(), [\"e.com\", \"a.com\", \"c.com\", \"d.com\"])\n",
    "  # Access \"f.com\".\n",
    "  cache.access_page(\"f.com\", \"FFF\")\n",
    "  # The cache is full, so we need to remove the least recently accessed page \"c.com\".\n",
    "  # The cache is updated to:\n",
    "  #   (most recently accessed)<-- \"f.com\", \"e.com\", \"a.com\", \"c.com\" -->(least recently accessed)\n",
    "  equal(cache.get_pages(), [\"f.com\", \"e.com\", \"a.com\", \"c.com\"])\n",
    "  print(\"OK!\")\n",
    "\n",
    "# A helper function to check if the contents of the two lists is the same.\n",
    "def equal(list1, list2):\n",
    "  assert(list1 == list2)\n",
    "  for i in range(len(list1)):\n",
    "    assert(list1[i] == list2[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
